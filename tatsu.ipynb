{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5209347,"sourceType":"datasetVersion","datasetId":3030040}],"dockerImageVersionId":30474,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-16T17:22:25.686301Z","iopub.execute_input":"2023-06-16T17:22:25.686904Z","iopub.status.idle":"2023-06-16T17:22:25.729717Z","shell.execute_reply.started":"2023-06-16T17:22:25.686856Z","shell.execute_reply":"2023-06-16T17:22:25.728213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://github.com/ctxj/Time-Series-Transformer-Pytorch/tree/main\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport copy\nimport math\nimport time\nimport matplotlib.pyplot as plt\n\nfrom torchinfo import summary\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:25.732012Z","iopub.execute_input":"2023-06-16T17:22:25.732486Z","iopub.status.idle":"2023-06-16T17:22:29.599292Z","shell.execute_reply.started":"2023-06-16T17:22:25.732451Z","shell.execute_reply":"2023-06-16T17:22:29.598337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"amzn_df = pd.read_csv(\"/kaggle/input/stock/Amazon.csv\")\nappl_df = pd.read_csv(\"/kaggle/input/stock/Apple.csv\")\ngoogl_df = pd.read_csv(\"/kaggle/input/stock/Google.csv\")\nmsft_df = pd.read_csv(\"/kaggle/input/stock/Microsoft.csv\")\nnflx_df = pd.read_csv(\"/kaggle/input/stock/Netflix.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.601608Z","iopub.execute_input":"2023-06-16T17:22:29.602565Z","iopub.status.idle":"2023-06-16T17:22:29.713087Z","shell.execute_reply.started":"2023-06-16T17:22:29.602527Z","shell.execute_reply":"2023-06-16T17:22:29.712071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_df = dict()\nstock_df['AMZN'] = amzn_df\nstock_df['APPL'] = appl_df\nstock_df['GOOGL'] = googl_df\nstock_df['MSFT'] = msft_df\nstock_df['NFLX'] = nflx_df","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.716771Z","iopub.execute_input":"2023-06-16T17:22:29.717065Z","iopub.status.idle":"2023-06-16T17:22:29.725472Z","shell.execute_reply.started":"2023-06-16T17:22:29.717041Z","shell.execute_reply":"2023-06-16T17:22:29.723472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"close_appl = stock_df['APPL'].Close","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.726636Z","iopub.execute_input":"2023-06-16T17:22:29.726969Z","iopub.status.idle":"2023-06-16T17:22:29.734663Z","shell.execute_reply.started":"2023-06-16T17:22:29.726937Z","shell.execute_reply":"2023-06-16T17:22:29.73361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_prices = np.diff(np.log(close_appl))","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.735972Z","iopub.execute_input":"2023-06-16T17:22:29.736572Z","iopub.status.idle":"2023-06-16T17:22:29.747641Z","shell.execute_reply.started":"2023-06-16T17:22:29.73654Z","shell.execute_reply":"2023-06-16T17:22:29.7454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_prices_csum = log_prices.cumsum() # Cumulative sum of log prices","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.75017Z","iopub.execute_input":"2023-06-16T17:22:29.75057Z","iopub.status.idle":"2023-06-16T17:22:29.757889Z","shell.execute_reply.started":"2023-06-16T17:22:29.750519Z","shell.execute_reply":"2023-06-16T17:22:29.756877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1, ax1 = plt.subplots(2, 1)\nax1[0].plot(close_appl, color='red')\nax1[0].set_title('Closed Price')\nax1[0].set_xlabel('Time Steps')\n\nax1[1].plot(log_prices_csum, color='blue')\nax1[1].set_title('CSUM of Log Price')\nax1[1].set_xlabel('Time Steps')\n\nfig1.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:29.76069Z","iopub.execute_input":"2023-06-16T17:22:29.761074Z","iopub.status.idle":"2023-06-16T17:22:30.282013Z","shell.execute_reply.started":"2023-06-16T17:22:29.761049Z","shell.execute_reply":"2023-06-16T17:22:30.281064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_CUDA = torch.cuda.is_available()\ndevice = torch.device('cuda:0' if USE_CUDA else 'cpu')\ninput_window = 7 # number of input time steps\noutput_window = 1 # number of prediction steps (equals to one)\nbatch_size = 100","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.283628Z","iopub.execute_input":"2023-06-16T17:22:30.283967Z","iopub.status.idle":"2023-06-16T17:22:30.317837Z","shell.execute_reply.started":"2023-06-16T17:22:30.283936Z","shell.execute_reply":"2023-06-16T17:22:30.3171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, dropout_p=0.1, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout_p)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return self.dropout(x + self.pe[:x.size(0), :])","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.322796Z","iopub.execute_input":"2023-06-16T17:22:30.323374Z","iopub.status.idle":"2023-06-16T17:22:30.333511Z","shell.execute_reply.started":"2023-06-16T17:22:30.32334Z","shell.execute_reply":"2023-06-16T17:22:30.33263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, feature_size=200, num_layers=2, dropout=0.1):\n        # feautre_size equals to embedding dimension (d_model)\n        super().__init__()\n        self.model_type = 'Transformer'\n\n        self.src_mask = None\n        self.pos_encoder = PositionalEncoding(feature_size)\n        \n        # Apply nhead multi-head attention\n        # d_key, d_query, d_value = d_model // n_head\n        self.encoder_layer = TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n        \n        # Use num_layers encoders\n        self.transformer_encoder = TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n        \n        # For simple time-series prediction, decoder just uses FC layer\n        self.decoder = nn.Linear(feature_size, 1)\n        self._init_weights()\n\n    def _init_weights(self):\n        init_range = 0.1\n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-init_range, init_range)\n\n    def forward(self, src):\n        if self.src_mask is None or self.src_mask.size(0) != len(src):\n            device = src.device\n            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n            self.src_mask = mask\n\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src, self.src_mask)\n        output = self.decoder(output)\n        return output\n\n    def _generate_square_subsequent_mask(self, size):\n        mask = torch.tril(torch.ones(size, size) == 1) # Lower Triangular matrix\n        mask = mask.float()\n        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n        return mask","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.335828Z","iopub.execute_input":"2023-06-16T17:22:30.337226Z","iopub.status.idle":"2023-06-16T17:22:30.351082Z","shell.execute_reply.started":"2023-06-16T17:22:30.337201Z","shell.execute_reply":"2023-06-16T17:22:30.350107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_inout_sequences(input_data, input_window):\n    inout_seq = []\n    L = len(input_data)\n    for i in range(L - input_window):\n        train_seq = input_data[i:i + input_window]\n        train_label = input_data[i + output_window: i + input_window + output_window]\n        inout_seq.append((train_seq, train_label))\n    return torch.FloatTensor(inout_seq)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.354406Z","iopub.execute_input":"2023-06-16T17:22:30.355176Z","iopub.status.idle":"2023-06-16T17:22:30.365484Z","shell.execute_reply.started":"2023-06-16T17:22:30.355145Z","shell.execute_reply":"2023-06-16T17:22:30.364481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(data_raw, split):\n    split = round(split * len(data_raw))\n    train_data = data_raw[:split]\n    test_data = data_raw[split:]\n\n    train_data = train_data.cumsum()\n    train_data = 2 * train_data  # Training data scaling\n\n    test_data = test_data.cumsum()\n\n    train_sequence = create_inout_sequences(train_data, input_window)\n    train_sequence = train_sequence[:-output_window]\n\n    test_sequence = create_inout_sequences(test_data, input_window)\n    test_sequence = test_sequence[:-output_window]\n\n    return train_sequence.to(device), test_sequence.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.368566Z","iopub.execute_input":"2023-06-16T17:22:30.368899Z","iopub.status.idle":"2023-06-16T17:22:30.379785Z","shell.execute_reply.started":"2023-06-16T17:22:30.368875Z","shell.execute_reply":"2023-06-16T17:22:30.378903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = get_data(log_prices, 0.7) # 70% for train and 30% for test","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:30.381084Z","iopub.execute_input":"2023-06-16T17:22:30.381585Z","iopub.status.idle":"2023-06-16T17:22:33.737348Z","shell.execute_reply.started":"2023-06-16T17:22:30.381553Z","shell.execute_reply":"2023-06-16T17:22:33.736379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_batch(source, i, batch_size):\n    seq_len = min(batch_size, len(source) - 1 - i)\n    data = source[i:i+seq_len]\n    data_in = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window, 1))\n    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window, 1))\n    return data_in, target","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:33.738538Z","iopub.execute_input":"2023-06-16T17:22:33.738898Z","iopub.status.idle":"2023-06-16T17:22:33.747084Z","shell.execute_reply.started":"2023-06-16T17:22:33.738867Z","shell.execute_reply":"2023-06-16T17:22:33.745391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_data):\n    model.train() # Turn on the evaluation mode\n    total_loss = 0.\n    start_time = time.time()\n\n    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n        data, targets = get_batch(train_data, i, batch_size)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, targets)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n        optimizer.step()\n\n        total_loss = total_loss + loss.item()\n        log_interval = int(len(train_data) / batch_size / 5)\n        if batch % log_interval == 0 and batch > 0:\n            cur_loss = total_loss / log_interval\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n                  'lr {:02.10f} | {:5.2f} ms | '\n                  'loss {:5.7f}'.format(\n                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n                    elapsed * 1000 / log_interval,\n                    cur_loss))\n            total_loss = 0\n            start_time = time.time()","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:33.748473Z","iopub.execute_input":"2023-06-16T17:22:33.749025Z","iopub.status.idle":"2023-06-16T17:22:33.760223Z","shell.execute_reply.started":"2023-06-16T17:22:33.748993Z","shell.execute_reply":"2023-06-16T17:22:33.759288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_source):\n    model.eval() # Turn on the evaluation mode\n    total_loss = 0.\n    eval_batch_size = 1000\n    with torch.no_grad():\n        for i in range(0, len(data_source) - 1, eval_batch_size):\n            data, targets = get_batch(data_source, i, eval_batch_size)\n            output = model(data)\n            total_loss = total_loss + len(data[0]) * criterion(output, targets).cpu().item()\n    return total_loss / len(data_source)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:33.763793Z","iopub.execute_input":"2023-06-16T17:22:33.764105Z","iopub.status.idle":"2023-06-16T17:22:33.775059Z","shell.execute_reply.started":"2023-06-16T17:22:33.764068Z","shell.execute_reply":"2023-06-16T17:22:33.774063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, sequences):\n    start_timer = time.time()\n    model.eval()\n    predicted_seq = torch.Tensor(0)\n    real_seq = torch.Tensor(0)\n    with torch.no_grad():\n        for i in range(0, len(sequences) - 1):\n            data, target = get_batch(sequences, i, 1)\n            output = model(data)\n            predicted_seq = torch.cat((predicted_seq, output[-1].view(-1).cpu()), 0)\n            real_seq = torch.cat((real_seq, target[-1].view(-1).cpu()), 0)\n    timed = time.time() - start_timer\n    print(f\"{timed} sec\")\n\n    return predicted_seq, real_seq","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:24.09442Z","iopub.execute_input":"2023-06-16T17:26:24.094796Z","iopub.status.idle":"2023-06-16T17:26:24.101946Z","shell.execute_reply.started":"2023-06-16T17:26:24.094765Z","shell.execute_reply":"2023-06-16T17:26:24.101001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Transformer().to(device)\n\ncriterion = nn.MSELoss() \nlr = 0.00005\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n\nN_EPOCHS = 150","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:33.790698Z","iopub.execute_input":"2023-06-16T17:22:33.791256Z","iopub.status.idle":"2023-06-16T17:22:33.903988Z","shell.execute_reply.started":"2023-06-16T17:22:33.791225Z","shell.execute_reply":"2023-06-16T17:22:33.902985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, N_EPOCHS + 1):\n    epoch_start_time = time.time()\n    train(train_data)\n\n    if (epoch % N_EPOCHS == 0):  # Valid model after last training epoch\n        val_loss = evaluate(model, test_data)\n        print('-' * 80)\n        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss: {:5.7f}'.format(epoch,\n                                                                                   (time.time() - epoch_start_time),\n                                                                                   val_loss))\n        print('-' * 80)\n\n    else:\n        print('-' * 80)\n        print('| end of epoch {:3d} | time: {:5.2f}s'.format(epoch, (time.time() - epoch_start_time)))\n        print('-' * 80)\n\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:22:33.905385Z","iopub.execute_input":"2023-06-16T17:22:33.905742Z","iopub.status.idle":"2023-06-16T17:23:17.725538Z","shell.execute_reply.started":"2023-06-16T17:22:33.90571Z","shell.execute_reply":"2023-06-16T17:23:17.724565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_seq, real_seq = predict(model, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:34.96394Z","iopub.execute_input":"2023-06-16T17:26:34.964349Z","iopub.status.idle":"2023-06-16T17:26:37.920924Z","shell.execute_reply.started":"2023-06-16T17:26:34.964316Z","shell.execute_reply":"2023-06-16T17:26:37.919802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig2, ax2 = plt.subplots(1, 1)\n\nax2.plot(predicted_seq, color='red', alpha=0.7)\nax2.plot(real_seq, color='blue', linewidth=0.7)\nax2.legend(['Actual', 'Forecast'])\nax2.set_xlabel('Time Steps')\nax2.set_ylabel('Log Prices')\n\nfig2.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:39.52543Z","iopub.execute_input":"2023-06-16T17:26:39.525802Z","iopub.status.idle":"2023-06-16T17:26:39.91529Z","shell.execute_reply.started":"2023-06-16T17:26:39.525774Z","shell.execute_reply":"2023-06-16T17:26:39.914337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"close_msft = stock_df['MSFT'].Close\nlog_prices2 = np.diff(np.log(close_msft))","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:53.463282Z","iopub.execute_input":"2023-06-16T17:26:53.463767Z","iopub.status.idle":"2023-06-16T17:26:53.470462Z","shell.execute_reply.started":"2023-06-16T17:26:53.463728Z","shell.execute_reply":"2023-06-16T17:26:53.46929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data2, test_data2 = get_data(log_prices2, 0.7)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:54.271657Z","iopub.execute_input":"2023-06-16T17:26:54.272095Z","iopub.status.idle":"2023-06-16T17:26:54.348232Z","shell.execute_reply.started":"2023-06-16T17:26:54.272059Z","shell.execute_reply":"2023-06-16T17:26:54.347188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_seq2, real_seq2 = predict(model, test_data2)","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:54.918046Z","iopub.execute_input":"2023-06-16T17:26:54.918405Z","iopub.status.idle":"2023-06-16T17:26:57.757638Z","shell.execute_reply.started":"2023-06-16T17:26:54.918369Z","shell.execute_reply":"2023-06-16T17:26:57.756655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig3, ax3 = plt.subplots(1, 1)\n\nax3.plot(predicted_seq2, color='red', alpha=0.7)\nax3.plot(real_seq2, color='blue', linewidth=0.7)\nax3.legend(['Actual', 'Forecast'])\nax3.set_xlabel('Time Steps')\nax3.set_ylabel('Log Prices')\n\nfig3.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-06-16T17:26:57.759623Z","iopub.execute_input":"2023-06-16T17:26:57.759983Z","iopub.status.idle":"2023-06-16T17:26:58.152409Z","shell.execute_reply.started":"2023-06-16T17:26:57.759949Z","shell.execute_reply":"2023-06-16T17:26:58.151388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}